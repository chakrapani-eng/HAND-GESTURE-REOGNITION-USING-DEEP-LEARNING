# HAND-GESTURE-REOGNITION-USING-DEEP-LEARNING
This model takes hand gesture images as input and gives the meaning of the gesture as output in the text form.

If you have GPU access in your laptop you an do it in jupyter notebook or whichever IDE you have. Since I dont have a GPU card I am performing this project on Google Colab since it provides free GPU for limited time.


YOU can access the free gpu in COLAB as: In colab interface go to EDIT>NOTEBOOKSETTINGS>HARDWAREACCELERATOR>GPU.
![image](https://user-images.githubusercontent.com/78845228/209652997-fef1971a-8595-412e-9583-09d4c6ef5722.png)


NOW insert every # in the code in each cell and run all the cells.
You can download the dataset from kaggle.
Uplaod the dataset in your google drive and copy the path to that dataset and paste it in the code.
![image](https://user-images.githubusercontent.com/78845228/209653536-c2b8fafc-80a9-4424-8848-4e141c672cc4.png)


Depending on the no.of gestures you provide,do the respective changes in (num_classes) and (dict_classes).
This model uses EFFICIENTNETV2 application.
For any queries you can mail me anytime[chakrapanimandlem09@gmail.com].
